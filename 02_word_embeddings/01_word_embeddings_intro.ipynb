{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb3589f",
   "metadata": {},
   "source": [
    "\n",
    "# What Are Embeddings?\n",
    "\n",
    "**Embeddings** are a way to represent text (**words, sentences, or documents**) as **numbers** so that computers can understand **meaning**, not just exact words.\n",
    "\n",
    "### In Simple Terms\n",
    "- Embeddings convert text into **vectors** (lists of numbers).\n",
    "- These vectors **capture the meaning** of the text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2cfb4",
   "metadata": {},
   "source": [
    "## Why Embeddings Are Needed\n",
    "\n",
    "- Computers **cannot understand human language directly**.\n",
    "- They can only process **numbers**.\n",
    "\n",
    "### Limitations of Older Methods\n",
    "- Traditional techniques like **TF-IDF** only **count word frequency**.\n",
    "- They **do not understand meaning or context**.\n",
    "\n",
    "### How Embeddings Help\n",
    "- **Embeddings** represent the **semantic meaning** of text.\n",
    "- This allows machines to understand **similarity and context**, not just exact words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb354c",
   "metadata": {},
   "source": [
    "\n",
    "## Simple Example (Human Meaning)\n",
    "\n",
    "These two sentences mean the same thing to humans:\n",
    "\n",
    "- *I love AI*  \n",
    "- *I enjoy artificial intelligence*\n",
    "\n",
    "**TF-IDF** → treats them as **different**  \n",
    "**Embeddings** → understand they are **similar**\n",
    "\n",
    "**That’s the power of embeddings.**\n",
    "\n",
    "\n",
    "## How Embeddings Work (Intuition)\n",
    "\n",
    "- Each word or sentence is converted into a **vector**  \n",
    "  (for example, **384** or **768** numbers).\n",
    "- **Similar meanings** → vectors are **close together**.\n",
    "- **Different meanings** → vectors are **far apart**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e04088",
   "metadata": {},
   "source": [
    "## Types of Embeddings\n",
    "\n",
    "### 1. Word Embeddings\n",
    "- Represent **individual words**.\n",
    "\n",
    "**Examples:**\n",
    "- Word2Vec  \n",
    "- GloVe  \n",
    "\n",
    "**Limitation:**\n",
    "- Same word → same vector  \n",
    "- No understanding of **context**\n",
    "\n",
    "\n",
    "### 2. Sentence Embeddings (Most Used Today)\n",
    "- Represent **full sentences or paragraphs**.\n",
    "\n",
    "**Examples:**\n",
    "- Sentence Transformers  \n",
    "- OpenAI embeddings  \n",
    "- Qwen / DeepSeek embeddings  \n",
    "\n",
    "**Used in:**\n",
    "- Semantic search  \n",
    "- RAG (Retrieval-Augmented Generation) systems  \n",
    "- Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2eea27",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a790c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae40ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    [\"I\", \"went\", \"to\", \"the\", \"bank\", \"to\", \"deposit\", \"money\"],\n",
    "    [\"The\", \"bank\", \"approved\", \"my\", \"loan\"],\n",
    "    [\"The\", \"river\", \"bank\", \"was\", \"flooded\"],\n",
    "    [\"We\", \"sat\", \"near\", \"the\", \"bank\", \"of\", \"the\", \"river\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bea7e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=50,\n",
    "    window=5,\n",
    "    min_count=1,\n",
    "    workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c536586e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector length: 50\n",
      "First 10 values of 'bank' embedding:\n",
      "[-0.00107245  0.00047286  0.0102067   0.01801855 -0.0186059  -0.01423362\n",
      "  0.01291774  0.01794598 -0.01003086 -0.00752674]\n"
     ]
    }
   ],
   "source": [
    "bank_vector = model.wv[\"bank\"]\n",
    "\n",
    "print(\"Vector length:\", len(bank_vector))\n",
    "print(\"First 10 values of 'bank' embedding:\")\n",
    "print(bank_vector[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47a6d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('money', 0.21057455241680145),\n",
       " ('loan', 0.16704076528549194),\n",
       " ('approved', 0.150198832154274),\n",
       " ('sat', 0.13204392790794373),\n",
       " ('river', 0.12667091190814972),\n",
       " ('flooded', 0.09980078041553497),\n",
       " ('went', 0.05936766415834427),\n",
       " ('I', 0.04979119822382927),\n",
       " ('the', 0.042373016476631165),\n",
       " ('my', 0.04067763686180115)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c02568",
   "metadata": {},
   "source": [
    "## Why This Happens (Important)\n",
    "\n",
    "The word **“bank”** appears in training data with **multiple meanings**:\n",
    "\n",
    "### Financial Bank\n",
    "- money  \n",
    "- loan  \n",
    "- approved  \n",
    "\n",
    "### River Bank\n",
    "- river  \n",
    "- flooded  \n",
    "\n",
    "### What Word2Vec Does\n",
    "- Word2Vec creates **one single vector** for the word **“bank”**.\n",
    "- Both meanings are **merged into that same vector**.\n",
    "\n",
    "### Result\n",
    "The model thinks:\n",
    "\n",
    "> **“bank” is related to both money and river**\n",
    "\n",
    "This is why **finance-related** and **river-related** words appear **together**.\n",
    "\n",
    "This is a key limitation of **word embeddings without context**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd2c9c8",
   "metadata": {},
   "source": [
    "# Sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81fca923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\Important\\Skills\\llm-learn\\env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eff5038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be813706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I love AI\",\n",
    "    \"I enjoy artificial intelligence\",\n",
    "    \"The weather is sunny\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909cecc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (sentence 1 & 2): 0.81963444\n",
      "Similarity (sentence 1 & 3): -0.0033589536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_1_2 = cosine_similarity(\n",
    "    [embeddings[0]], [embeddings[1]]\n",
    ")\n",
    "\n",
    "similarity_1_3 = cosine_similarity(\n",
    "    [embeddings[0]], [embeddings[2]]\n",
    ")\n",
    "\n",
    "print(\"Similarity (sentence 1 & 2):\", similarity_1_2[0][0])\n",
    "print(\"Similarity (sentence 1 & 3):\", similarity_1_3[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced8ab0f",
   "metadata": {},
   "source": [
    "## Key Takeaway\n",
    "\n",
    "- **Sentence embeddings** represent **meaning**, not just individual words.\n",
    "- **Similar meanings** → **similar vectors**.\n",
    "- They are **essential** for modern **NLP** and **LLM pipelines**.\n",
    "- **RAG (Retrieval-Augmented Generation) systems** rely heavily on **sentence embeddings**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59374517",
   "metadata": {},
   "source": [
    "# Why do sentence embeddings work better than word embeddings for semantic search?\n",
    "Sentence embeddings work better than word embeddings for semantic search because they capture the meaning of the entire sentence in context, while word embeddings represent individual words without context.\n",
    "\n",
    "Word embeddings assign the same vector to a word everywhere, so different meanings get mixed. Sentence embeddings change based on surrounding words, allowing them to understand intent, synonyms, and context, which leads to more accurate semantic search results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
